# -- IMPORTS START --
import warnings
import pandas as pd
import glob
import re
import os
import sys
import pickle
import numpy as np
import matplotlib
import matplotlib.pyplot as plt

from sklearn import tree, metrics
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay
from scipy.signal import butter, filtfilt, find_peaks
from sklearn.tree import DecisionTreeClassifier,export_graphviz
from sklearn.model_selection import train_test_split
# -- IMPORTS END --

# enable zooming into graphs
%matplotlib notebook
plt.rcParams['figure.figsize'] = [9, 6] # width, height in inches


# Helper function to visualize model - Do not modify
def viz_tree(dt_model,features_frames,cnames):
    # Fix feature names as list
    feature_names = features_frames.columns.tolist()

    fig, ax = plt.subplots(figsize=(9,4))
    tree.plot_tree(dt_model,  
                   feature_names=feature_names,
                   fontsize=7,
                   class_names=cnames,
                   filled=True,
                   ax=ax)

    plt.title('Decision Tree')
    plt.savefig('dt.png')


def calc_magnitude(data):

    # Calculate magnitude  
    data['accel_mag'] = np.sqrt(data['x']**2 + data['y']**2 + data['z']**2) # absolute accel magnitude
    data['accel_mag'] = data['accel_mag'] - data['accel_mag'].mean() # detrend: "remove gravity"

    return data


def remove_noise(data,sampling_rate):
    from scipy.signal import butter, filtfilt, find_peaks

    # Low pass filter
    cutoff = 5 # Hz
    order = 2
    b, a = butter(order, cutoff/(sampling_rate/2), btype='lowpass')
    data['filtered_accel_mag'] = filtfilt(b, a, data['accel_mag'])

    return data


def add_features(window):
    features = {}
    features['avg'] = window['accel_mag'].mean()
    features['max'] = window['accel_mag'].quantile(1)
    features['med'] = window['accel_mag'].quantile(0.5)
    features['min'] = window['accel_mag'].quantile(0)
    features['q25'] = window['accel_mag'].quantile(0.25)
    features['q75'] = window['accel_mag'].quantile(0.75)
    features['std'] = window['accel_mag'].std()
    #features['var'] = window['accel_mag'].var()
    
    df = pd.DataFrame()
    df = df.append(features,ignore_index=True)
    return df


def train_decision_tree(frames):
    
    #original code
    # Extract feature columns 
    X = frames[['avg', 'max', 'med', 'min', 'q25', 'q75', 'std']]

    # Extract target column
    y = frames['activity']

    # #split DataFrame into a features matrix X and a labels vector y
    # # drops the last column in the dataframe
    # X = frames.iloc[:, :-1]
    # # X = frames.drop("activity", axis = 'columns')
    # y = frames['activity']

    # Split data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) 

    # Create model
    dt_model = DecisionTreeClassifier(criterion='entropy',max_depth=5).fit(X_train, y_train)
    dt_pred = dt_model.predict(X_test)

    # Evaluate on test set
    acc = dt_model.score(X_test, y_test)
    dt_cm = confusion_matrix(y_test, dt_pred, labels=dt_model.classes_)
    print(classification_report(y_test, dt_pred))
    print("Accuracy on test set:", acc)

    return dt_model,dt_cm,acc


def classify_live_window(df):
    
    # Filter accelerometer data 
    df_accel = df[df['accel_x'].notna() & df['accel_y'].notna() & df['accel_z'].notna()]
    df_valid = df_accel[['accel_x', 'accel_y', 'accel_z']].rename(columns={
      'accel_x': 'x',
      'accel_y': 'y',
      'accel_z': 'z'  
    })

    # Calculate accel_mag
    df_valid = calc_magnitude(df_valid) 

    # Add features
    df_valid = add_features(df_valid) 
    X = df_valid[['avg', 'max', 'med', 'min', 'q25', 'q75',  'std']] 

    # Load model
    with open('dt_model.pkl', 'rb') as f:
        model = pickle.load(f)
        
    # Make prediction
    y_pred = model.predict(df_valid)

    return(y_pred)


def test_live_classification(): # Testing the live model
    # Generate sample DataFrame
    data = {'accel_x': [0.011531], 
            'accel_y': [0.002931],
            'accel_z': [0.019604],
            'time': ['2023-08-01 18:40:43.344408']}

    df = pd.DataFrame(data)

    # Repeat rows to get 1000 rows
    df = pd.concat([df]*1000, ignore_index=True) 

    # Call function
    y_pred = classify_live_window(df)

    print(y_pred)


# Function to extract windows and features 
def extract_features(data, window_sec, sample_rate, activity): 

    STEP_MAX = 2
    STEP_MIN = 1
    VAR_THRESHOLD = 0.10

    
    # TODO - see instructions above
    frame = pd.DataFrame()
    data = calc_magnitude(data)
    data = remove_noise(data, sample_rate)

    data['time'] = pd.to_datetime(data['time'])
    data.set_index('time', inplace = True)
    
    resampler = data.resample(f'{window_sec}S')
    
    for window_activity, window_data in resampler:
        features = add_features(window_data)
        var = window_data['filtered_accel_mag'].var()
        
        peaks, _ = find_peaks(window_data['filtered_accel_mag'], height=0.2, prominence=0.1, distance=2)
        detected_peaks = len(peaks)
        
        if (detected_peaks > STEP_MAX) and (var > VAR_THRESHOLD):
            activity = 'falling'
        elif (detected_peaks > STEP_MIN) and (detected_peaks < STEP_MAX):
            activity = 'walking'
        else:
            activity = 'other'
        
        features['activity'] = activity
        frame = frame.append(features, ignore_index = True)

    return frame


def all_data_to_combined_csv():
    import os
    import sys

    # TODO - see instructions above
    # there is nothing to return from this function. 
    # The function is writing something to a file instead.
    window_sec = 10
    sample_rate = 100
    
    # initializes dataframe
    all_data = pd.DataFrame()

    # list of activites in the data that we are iterating through
    activities = ["downstairs", "jogging", "lying", "sitting", "standing", "upstairs", "walk_fast", "walk_mod", "walk_slow"]

    for activity in activities:

        # getting the path to the specific activity's folder
        path = 'data/Activities'
        file_path = os.path.join(path, activity, '*.csv')
    
        # only conglomerates the files from the specific activity passed in
        files = glob.glob(file_path)

    
        for filename in files:
            data = pd.read_csv(filename)
    
            data = calc_magnitude(data)
            data = remove_noise(data, sample_rate)

            # same code from last time to convert timestamps
            data['time'] = pd.to_datetime(data['time'])
            data.set_index('time', inplace = True)
    
            # extracts activity from data
            activity = os.path.basename(os.path.dirname(filename))
    
            features = extract_features(data, window_sec, sample_rate, activity)
    
            all_data = all_data.append(features, ignore_index = True)

    
    # writing dataframe to csv file
    all_data.to_csv('all_data.csv', index = False)


warnings.filterwarnings('ignore')
%matplotlib inline

# Create a new dataset that extracts features from all the files and labels them with the corresponding activity
# This function will only create the all_data.csv file once. If you want to overwrite, delete the file first.
#all_data_to_combined_csv()

#feature_frames = pd.read_csv('data/Activities/all_data.csv')


# had to call extract features because we are no longer calling all_data_to_combined_csv()
feature_frames = pd.read_csv('data/fall-detection-training-data.csv')
feature_frames = calc_magnitude(feature_frames)
feature_frames = remove_noise(feature_frames, 100)
feature_frames = extract_features(feature_frames, 5, 100, 'falling')
print(feature_frames)


# Activities to drop - pick a subset of the below activities to drop and see how accuracy changes
all_activities = ['falling', 'walking', 'other']
drop_activities = []


# TODO: Invert mask to keep only other rows

feature_frames = feature_frames[~feature_frames['activity'].isin(drop_activities)]


# TODO: Train the decision tree with the chosen classes
# This function will print out precision/recall/accuracy

dt_model, dt_cm, acc = train_decision_tree(feature_frames)


# TODO: Save the classifier to disk. The name should be exactly dt_model.pkl

with open('dt_model.pkl', 'wb') as file:
    pickle.dump(dt_model, file)

# TODO: Display the confusion matrix

display = ConfusionMatrixDisplay(confusion_matrix=dt_cm, display_labels=feature_frames['activity'].unique())
display.plot(cmap='Blues')
plt.show()

# TODO: Visualize the tree
cnames = list(set(all_activities) - set(drop_activities))

viz_tree(dt_model,feature_frames,cnames)


test_live_classification()
