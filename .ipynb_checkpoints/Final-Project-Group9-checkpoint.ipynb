{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0cdc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- IMPORTS START --\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import tree, metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from scipy.signal import butter, filtfilt, find_peaks\n",
    "from sklearn.tree import DecisionTreeClassifier,export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "# -- IMPORTS END --\n",
    "\n",
    "# enable zooming into graphs\n",
    "%matplotlib notebook\n",
    "plt.rcParams['figure.figsize'] = [9, 6] # width, height in inches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c19f3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to visualize model - Do not modify\n",
    "def viz_tree(dt_model,features_frames,cnames):\n",
    "    # Fix feature names as list\n",
    "    feature_names = features_frames.columns.tolist()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9,4))\n",
    "    tree.plot_tree(dt_model,  \n",
    "                   feature_names=feature_names,\n",
    "                   fontsize=7,\n",
    "                   class_names=cnames,\n",
    "                   filled=True,\n",
    "                   ax=ax)\n",
    "\n",
    "    plt.title('Decision Tree')\n",
    "    plt.savefig('dt.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0523e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do not modify\n",
    "def calc_magnitude(data):\n",
    "\n",
    "    # Calculate magnitude  \n",
    "    data['accel_mag'] = np.sqrt(data['x']**2 + data['y']**2 + data['z']**2) # absolute accel magnitude\n",
    "    data['accel_mag'] = data['accel_mag'] - data['accel_mag'].mean() # detrend: \"remove gravity\"\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cdec47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do not modify\n",
    "def remove_noise(data,sampling_rate):\n",
    "    from scipy.signal import butter, filtfilt, find_peaks\n",
    "\n",
    "    # Low pass filter\n",
    "    cutoff = 5 # Hz\n",
    "    order = 2\n",
    "    b, a = butter(order, cutoff/(sampling_rate/2), btype='lowpass')\n",
    "    data['filtered_accel_mag'] = filtfilt(b, a, data['accel_mag'])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d833e7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do not modify\n",
    "def add_features(window):\n",
    "    features = {}\n",
    "    features['avg'] = window['accel_mag'].mean()\n",
    "    features['max'] = window['accel_mag'].quantile(1)\n",
    "    features['med'] = window['accel_mag'].quantile(0.5)\n",
    "    features['min'] = window['accel_mag'].quantile(0)\n",
    "    features['q25'] = window['accel_mag'].quantile(0.25)\n",
    "    features['q75'] = window['accel_mag'].quantile(0.75)\n",
    "    features['std'] = window['accel_mag'].std()\n",
    "    df = pd.DataFrame()\n",
    "    df = df.append(features,ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a70af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_decision_tree(frames):\n",
    "    # Extract feature columns \n",
    "    X = frames[['avg', 'max', 'med', 'min', 'q25', 'q75', 'std']]\n",
    "\n",
    "    # Extract target column\n",
    "    y = frames['activity']\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) \n",
    "\n",
    "    # Create model\n",
    "    dt_model = DecisionTreeClassifier(criterion='entropy',max_depth=5).fit(X_train, y_train)\n",
    "    dt_pred = dt_model.predict(X_test)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    acc = dt_model.score(X_test, y_test)\n",
    "    dt_cm = confusion_matrix(y_test, dt_pred, labels=dt_model.classes_)\n",
    "    print(classification_report(y_test, dt_pred))\n",
    "    print(\"Accuracy on test set:\", acc)\n",
    "\n",
    "    return dt_model,dt_cm,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bb66dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_live_window(df):\n",
    "    \n",
    "    # Filter accelerometer data \n",
    "    df_accel = df[df['accel_x'].notna() & df['accel_y'].notna() & df['accel_z'].notna()]\n",
    "    df_valid = df_accel[['accel_x', 'accel_y', 'accel_z']].rename(columns={\n",
    "      'accel_x': 'x',\n",
    "      'accel_y': 'y',\n",
    "      'accel_z': 'z'  \n",
    "    })\n",
    "\n",
    "    # Calculate accel_mag\n",
    "    df_valid = calc_magnitude(df_valid) \n",
    "\n",
    "    # Add features\n",
    "    df_valid = add_features(df_valid) \n",
    "    X = df_valid[['avg', 'max', 'med', 'min', 'q25', 'q75',  'std']] \n",
    "\n",
    "    # Load model\n",
    "    with open('dt_model.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "        \n",
    "    # Make prediction\n",
    "    y_pred = model.predict(df_valid)\n",
    "\n",
    "    return(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4142595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_live_classification(): # Testing the live model\n",
    "    # Generate sample DataFrame\n",
    "    data = {'accel_x': [0.011531], \n",
    "            'accel_y': [0.002931],\n",
    "            'accel_z': [0.019604],\n",
    "            'time': ['2023-08-01 18:40:43.344408']}\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Repeat rows to get 1000 rows\n",
    "    df = pd.concat([df]*1000, ignore_index=True) \n",
    "\n",
    "    # Call function\n",
    "    y_pred = classify_live_window(df)\n",
    "\n",
    "    print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad9a980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract windows and features \n",
    "def extract_features(data, window_sec, sample_rate, activity):\n",
    "    # TODO - see instructions above\n",
    "    frame = pd.DataFrame()\n",
    "    data = calc_magnitude(data)\n",
    "    data = remove_noise(data, sample_rate)\n",
    "    \n",
    "    resampled = data.resample(f'{window_sec}S')\n",
    "    \n",
    "    for window_activity, window_data in resampled:\n",
    "        features = add_features(window_data)\n",
    "        features['activity'] = activity\n",
    "        frame = frame.append(features, ignore_index = True)\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd9717a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_data_to_combined_csv():\n",
    "    import os\n",
    "    import sys\n",
    "\n",
    "    # TODO - see instructions above\n",
    "    # there is nothing to return from this function. \n",
    "    # The function is writing something to a file instead.\n",
    "    window_sec = 10\n",
    "    sample_rate = 100\n",
    "    \n",
    "    # initializes dataframe\n",
    "    all_data = pd.DataFrame()\n",
    "\n",
    "    # list of activites in the data that we are iterating through\n",
    "    activities = [\"downstairs\", \"jogging\", \"lying\", \"sitting\", \"standing\", \"upstairs\", \"walk_fast\", \"walk_mod\", \"walk_slow\"]\n",
    "\n",
    "    for activity in activities:\n",
    "\n",
    "        # getting the path to the specific activity's folder\n",
    "        path = 'data/Activities'\n",
    "        file_path = os.path.join(path, activity, '*.csv')\n",
    "    \n",
    "        # only conglomerates the files from the specific activity passed in\n",
    "        files = glob.glob(file_path)\n",
    "\n",
    "    \n",
    "        for filename in files:\n",
    "            data = pd.read_csv(filename)\n",
    "    \n",
    "            data = calc_magnitude(data)\n",
    "            data = remove_noise(data, sample_rate)\n",
    "\n",
    "            # same code from last time to convert timestamps\n",
    "            data['time'] = pd.to_datetime(data['time'])\n",
    "            data.set_index('time', inplace = True)\n",
    "    \n",
    "            # extracts activity from data\n",
    "            activity = os.path.basename(os.path.dirname(filename))\n",
    "    \n",
    "            features = extract_features(data, window_sec, sample_rate, activity)\n",
    "    \n",
    "            all_data = all_data.append(features, ignore_index = True)\n",
    "\n",
    "    \n",
    "    # writing dataframe to csv file\n",
    "    all_data.to_csv('all_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c981814",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "# Create a new dataset that extracts features from all the files and labels them with the corresponding activity\n",
    "# This function will only create the all_data.csv file once. If you want to overwrite, delete the file first.\n",
    "all_data_to_combined_csv()\n",
    "\n",
    "#feature_frames = pd.read_csv('data/Activities/all_data.csv')\n",
    "feature_frames = pd.read_csv('all_data.csv')\n",
    "\n",
    "# Activities to drop - pick a subset of the below activities to drop and see how accuracy changes\n",
    "all_activities = ['downstairs','jogging','lying','sitting','standing','upstairs','walk_fast','walk_mod','walk_slow']\n",
    "# drop_activities = ['downstairs','jogging','lying','sitting','standing','upstairs']\n",
    "# drop_activities = ['jogging','lying','sitting','standing','walk_fast','walk_mod','walk_slow']\n",
    "# drop_activities = ['downstairs','jogging','upstairs','walk_fast','walk_mod','walk_slow']\n",
    "# drop_activities = ['lying','sitting','standing']\n",
    "# drop_activities = []\n",
    "\n",
    "\n",
    "# TODO: Invert mask to keep only other rows\n",
    "\n",
    "feature_frames = feature_frames[~feature_frames['activity'].isin(drop_activities)]\n",
    "\n",
    "# TODO: Train the decision tree with the chosen classes\n",
    "# This function will print out precision/recall/accuracy\n",
    "\n",
    "dt_model, dt_cm, acc = train_decision_tree(feature_frames)\n",
    "\n",
    "\n",
    "# TODO: Save the classifier to disk. The name should be exactly dt_model.pkl\n",
    "\n",
    "with open('dt_model.pkl', 'wb') as file:\n",
    "    pickle.dump(dt_model, file)\n",
    "\n",
    "# TODO: Display the confusion matrix\n",
    "\n",
    "display = ConfusionMatrixDisplay(confusion_matrix=dt_cm, display_labels=feature_frames['activity'].unique())\n",
    "display.plot(cmap='Blues')\n",
    "plt.show()\n",
    "\n",
    "# TODO: Visualize the tree\n",
    "cnames = list(set(all_activities) - set(drop_activities))\n",
    "\n",
    "viz_tree(dt_model,feature_frames,cnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b41a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_live_classification()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
